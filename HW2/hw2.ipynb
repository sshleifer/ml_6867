{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.optimize import minimize\n",
    "from sklearn import clone\n",
    "from tqdm import tqdm\n",
    "import funcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hw2_resources.plotBoundary import plotDecisionBoundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code.helpers import read_in, plotDecisionBoundary, make_fname\n",
    "from code.problem1 import nll, l1_reg, l2_reg, LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression\n",
    "1. Note: Sklearn uses C = 1/λ\n",
    "2. See `intercept_scaling` in sklearn.\n",
    "3. When you report weights, include `W0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ NLL(w, w0) =  \\sum(log (1 + exp  (−y(i)(wx(i) + w0))))$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$ NLL(w, w0) =  \\sum(log (1 + exp  (−y(i)(wx(i) + w0))))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "2. Why different coeffs than sklearn?\n",
    "3. Compare L=1 to L=0\n",
    "4. Results tables\n",
    "5. Decision boundaries?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = read_in(data=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = LogReg(reg_func=l2_reg, L=0.).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94499999999999995"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probas = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yhat = clf.predict(X)\n",
    "(np.sign(yhat) == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94499999999999995"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(fit_intercept=True, C=1e9).fit(X, Y)\n",
    "yhat = clf.predict(X)\n",
    "cof = np.squeeze(clf.coef_)\n",
    "cof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lin_reg(minimize(nll, np.copy(w)).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minimize(funcy.partial(nll, L=1., reg_func=l1_reg), np.copy(w)).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minimize(funcy.partial(nll, L=1., reg_func=l2_reg), np.copy(w)).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LogisticRegression(C=.01, penalty='l2').fit(X,Y).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_log = LogisticRegression(C=.01, penalty='l1')\n",
    "l2_log = LogisticRegression(C=.01, penalty='l2')\n",
    "lr_no_reg = LogisticRegression(C=1e12, penalty='l2')\n",
    "#.fit(X,Y).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def all_stats():\n",
    "    res ={}\n",
    "    for d in [1,2,3,4]:\n",
    "        for C in [.0001, .001, .01,1, 1e12]:\n",
    "            for pen in [ 'l2']:\n",
    "                clf = LogisticRegression(C=C, penalty=pen)\n",
    "                #clf = LogisticRegressionCV(penalty=pen)\n",
    "\n",
    "                res[(d,C, pen)] = get_stats(d, clf)\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_stats(data, clf):\n",
    "    X, Y = read_in(data=data, suffix='train')\n",
    "    \n",
    "    Xt, Yt = read_in(data=data, suffix='test')\n",
    "    Xv, Yv = read_in(data=data, suffix='validate')\n",
    "    clf.fit(X, Y)\n",
    "    return pd.Series(dict(te_score = clf.score(Xt, Yt),\n",
    "                          tr_score = clf.score(X, Y),\n",
    "                          val_score = clf.score(Xv, Yv),\n",
    "                          weight_norm  = np.sum(np.abs(clf.coef_)),\n",
    "                          clf=clf)) \n",
    "    \n",
    "    \n",
    "#l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res  =all_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = pd.DataFrame(res).rename_axis(['data', 'C', 'Penalty'], 1).loc['clf'].iloc[0]#.get_params()#T[['tr_score', 'oos_score', 'weight_norm']].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " pd.DataFrame(res).rename_axis(['data', 'C', 'Penalty'], 1).loc['clf'].iloc[0]#.get_params()#T[['tr_score', 'oos_score', 'weight_norm']].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.loadtxt('hw2_resources/data/data'+name+'_test.csv')\n",
    "Xt = test[:,0:2]\n",
    "onz = np.ones(Xt.shape[0])\n",
    "Xt = np.hstack([Xt, onz.reshape(Xt.shape[0],1)])\n",
    "Yt= np.ravel(test[:,2:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-32fefad02935>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m  \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreg_cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0myhat\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m  \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xv' is not defined"
     ]
    }
   ],
   "source": [
    "kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "val_error(w_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_error(w_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wL, pL = _gradient_descent(funcy.partial(nll, L=1.), init_weights=np.copy(w), lr=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_error(wL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_error(wL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wL1, pL1 = _gradient_descent(funcy.partial(nll, L=1., reg_func=l1_reg),\n",
    "                             init_weights=np.copy(w), lr=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_error(wL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = paths[['w_0', 'w_1', 'w_2']].plot()\n",
    "ax.set_title('No Regularization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.copy(w) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = pL[['w_0', 'w_1', 'w_2']].plot()\n",
    "ax.set_title('L2 Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = pL1[['w_0', 'w_1', 'w_2']].plot()\n",
    "ax.set_title('L1 Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pL1[['w_0', 'w_1', 'w_2']].diff().abs().tail(20).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%latex\n",
    "$\\bf{1.1}$ With $\\lambda$ = 0, the weight vector takes longer to converge, as the weights keep expanding away from 0 for longer.\n",
    "When we add the $L2$ regularization penalty, with $\\lambda$=1, it takes only 90 iterations to achieve convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%latex\n",
    "$\\bf{1.2}$ When we add the $L1$ regularization penalty, with $\\lambda$=1, it takes  more iterations to achieve convergence because the coefficients that drop out bounce around zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Implement Dual Form of linear SVM with slack variables\n",
    "\n",
    "### Intro Notes\n",
    "- Weight vector w as weighted linear combination of instances\n",
    "- Only points on margin matter; ignore the rest, solution remains\n",
    "unchanged\n",
    "- Keeps instances away from the margin\n",
    "- \"Finding the minimum error separating hyperplane is NP-hard\" \n",
    "\n",
    "- f(x) = <w, x> + b\n",
    "\n",
    "\n",
    "### TODO:\n",
    "- verify get_theta division\n",
    "- tables, figures for writeup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%latex\n",
    "For linear SVM, $w = \\sum{y_{i}a_{i}x_{i}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cvxopt import matrix, solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def train_svm(X, y, kernel=linear_kernel, C=1.):\n",
    "n_samples, n_features = X.shape\n",
    "y = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_vec = X.dot(X[0])\n",
    "kernel  = linear_kernel\n",
    "C = 1.\n",
    "LINEAR_KERNEL = np.dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del get_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_theta(sv, svy, ind, alpha, K, non_zero_mask):\n",
    "        theta_0 = 0   #intercept\n",
    "        for n in range(len(alpha)):\n",
    "            theta_0 +=  (svy[n] - np.sum(alpha *svy * K[ind[n],  non_zero_mask]))\n",
    "            theta_0 /= len(alpha)  # seems wierd\n",
    "        return theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SVMD(object):\n",
    "    def __init__(self, X, y, kernel=LINEAR_KERNEL, C=1.):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.X =  X\n",
    "        self.y = y\n",
    "        self.C = C\n",
    "        self.K = np.array([[kernel(X[i], X[j]) for i in range(n_samples)] for j in range(n_samples)])\n",
    "        self.kernel = kernel\n",
    "        self.n_features = X.shape[1]\n",
    "        self.solution = self.train()\n",
    "        alpha, ind, mask = self.inspect(self.solution)\n",
    "        svx = self.X[mask]\n",
    "        svy = self.y[mask]\n",
    "        self.svx, self.svy, self.ind, self.alpha, self.mask = svx, svy, ind, alpha[mask], mask\n",
    "\n",
    "    def fit(self):\n",
    "        self.theta = get_theta(self.svx, self.svy,  self.ind, self.alpha, self.K, self.mask)\n",
    "        return self\n",
    "    \n",
    "    def train(self):\n",
    "        X,y, kernel, C = self.X, self.y, self.kernel, self.C  # to avoid typing self\n",
    "        n_samples, n_features = X.shape\n",
    "        P= matrix(np.outer(y,y) *self.K)\n",
    "        q= matrix(np.ones(n_samples)*-1.)\n",
    "        A = matrix(y, (1, n_samples))\n",
    "        b = matrix(0.)\n",
    "        G = matrix(np.vstack([np.diag(np.ones(n_samples)) * -1, np.diag(np.ones(n_samples))]))\n",
    "        h = matrix(np.hstack([np.zeros(n_samples), self.C *np.ones(n_samples)]))\n",
    "        return solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def inspect(solution, cutoff=1e-5):\n",
    "        alpha = np.ravel(solution['x'])\n",
    "        non_zero_mask = alpha > cutoff\n",
    "        ind = np.arange(len(alpha))[non_zero_mask]\n",
    "        print ind.mean()\n",
    "        return alpha,ind, non_zero_mask\n",
    "    \n",
    "    def predict(self, X_new):\n",
    "        self.weights = (self.alpha*self.svy).dot(self.svx)\n",
    "        self.margin = 1./ norm(self.weights)\n",
    "        if self.kernel == linear_kernel:    \n",
    "            return np.sign(np.dot(X_new, self.weights) + self.theta)\n",
    "        else:\n",
    "            pred_val = [np.sum([a*y*clf.kernel(X[i], x) for a,y,x in zip(clf.alpha, clf.svy, clf.svx)]) for i in range(X_new.shape[0])]\n",
    "            self.margin = None\n",
    "            return np.sign(np.array(pred_val) + self.theta)\n",
    "\n",
    "    def score(self, X_new, y_new):\n",
    "        yhat = self.predict(X_new)\n",
    "        assert yhat.shape ==  y_new.shape, \"Shape mismatch\"\n",
    "        return (yhat == y_new).mean()\n",
    "    def plot_boundary(self, X, y, **kwargs):\n",
    "        return plotDecisionBoundary(X,y, self.predict, [-1,0,1], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = SVMD(X, Y, kernel=gaussian_kernel, C=10.).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt, Yt = read_in(data=4, suffix='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_stats(data, C=1., **kwargs):\n",
    "    X, Y = read_in(data=data, suffix='train')\n",
    "    Xt, Yt = read_in(data=data, suffix='test')\n",
    "    Xv, Yv = read_in(data=data, suffix='validate')\n",
    "    clf = SVMD(X, Y, C=C, **kwargs).fit()\n",
    "    assert clf.C == C, 'clf.c={}'.format(clf.C)\n",
    "    clf.score(Xt, Yt)\n",
    "    return pd.Series(dict(n_sv=len(clf.alpha),\n",
    "                          tr_score = clf.score(X, Y),\n",
    "                          te_score = clf.score(Xt, Yt),\n",
    "                          val_score = clf.score(Xv, Yv),\n",
    "                          margin=clf.margin,\n",
    "                          weights = clf.weights,\n",
    "                          clf=clf\n",
    "                         )) \n",
    "\n",
    "del X, Y\n",
    "X, Y = read_in(data=1, suffix='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "res  = pd.DataFrame({d:get_stats(d) for d in [1,2,3,4]}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# res.loc[1].clf.ind \n",
    "assert res.loc[1].clf.ind[0] ==16, 'something changed upstream'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tab = 1- res.drop('clf', 1)[['tr_score', 'val_score']].rename_axis('2D Dataset')\n",
    "tab.columns = ['Training Error', 'Validation Error']\n",
    "#print tab.to_latex()\n",
    "#tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_plots(res=res):\n",
    "    suffix = 'train'\n",
    "    for k, row in res.iterrows():\n",
    "        v = row.clf    \n",
    "        X, y = read_in(k, suffix=suffix)\n",
    "        score = v.score(X,y)\n",
    "        v.plot_boundary(X,y, \n",
    "                        title='{} data {}, score={}'.format(suffix, k, score, row.weights)\n",
    "                       )\n",
    "        pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Kernels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.0 Notes\n",
    "- Increasing C allows for more nonlinearities\n",
    "- Decreases # errpors\n",
    "- SV boundary may not be contiguous\n",
    "- Kernel width adjusts function class\n",
    "\n",
    "### 2.3.1 Extend code to handle Gaussian RBF kernel\n",
    "\n",
    "**(A)** What happens to the geometric meargin `1/|w|` as `C`  increases? Will this always happen when we increase C?\n",
    "\n",
    "**(B)** What happens to the number of support vectors as C increases?\n",
    "\n",
    "**(C)**Why would maximizing the geometric margin `1/||w||` on the training set not be an appropriate criterion for selecting C? Is there an alternative criterion that we could use for this purpose?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def polynomial_kernel(x, y, p=3):\n",
    "    return (1 + np.dot(x, y)) ** p\n",
    "\n",
    "def gaussian_kernel(x,y, sigma=1.):\n",
    "    return np.exp(-norm(x-y)**2 / 2 * (sigma **2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ggplot import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,Y = read_in(data=4, suffix='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "clf = SVMD(X, Y, kernel=gaussian_kernel).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.score(clf.X, clf.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " clf.kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "lin = SVMD(X, Y, kernel=LINEAR_KERNEL).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y = read_in(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = LinearSVC(loss='hinge').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LinearSVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Tables describing Parameter search of `C` and `sigma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "CRange = {.01, .1, 1, 10, 100}\n",
    "SRange = {.001, .01, .1, 1, 10}\n",
    "\n",
    "c_gauss_results = pd.concat([\n",
    "        pd.DataFrame({d:get_stats(d, kernel=funcy.partial(gaussian_kernel, sigma=s), C=c) \n",
    "                      for d in [1,2,3,4]}).T.assign(c=c, signma=s)\n",
    "        for c in CRange\n",
    "        for s in SRange\n",
    "    ]).rename_axis(['data'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "c_lin_results = pd.concat([\n",
    "        pd.DataFrame({d:get_stats(d,C=c) for d in [1,2,3,4]}).T.assign(c=c)\n",
    "        for c in CRange]).rename_axis(['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_lin_results.loc[1].iloc[-1].clf.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_lin_results.set_index('c', append=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_gauss_results.set_index('c', append=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_plots(res_gauss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pegasos\n",
    "**(2)** Observe the the margin (distance between the decision boundary and margin boundary) as a function of L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_EPOCHS =1e4\n",
    "def pegasos(X, y,L=2, max_epochs=MAX_EPOCHS):\n",
    "    N = np.array([1. / (t*L) for t in range(1, int(MAX_EPOCHS *2))])\n",
    "    w =np.zeros(X.shape[1])\n",
    "    t = 0\n",
    "    while t < max_epochs:\n",
    "        for i, row in enumerate(X):\n",
    "            t +=1\n",
    "            w = (1 - N[t]*L) * w\n",
    "            if y[i]* w.T.dot(row) < 1:\n",
    "                w = w + N[t]*y[i]*row\n",
    "    return w\n",
    "\n",
    "class Pegasos(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X,y, **kwargs):\n",
    "        self.coef_ = pegasos(X,y, **kwargs)\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return X.dot(self.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = Pegasos().fit(X, y)\n",
    "plotDecisionBoundary(X,y, p.predict, [-1,0,1], title='Pegasos SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plotDecisionBoundary(X[:4], y[:4], clf.predict, [-1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC().fit(X, y)\n",
    "print clf.coef_\n",
    "plotDecisionBoundary(X[:4], y[:4], clf.predict, [-1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotDecisionBoundary(X,np.array(y), clf.predict, [-1,0,1], title='Pegasos SVM, l={}'.format(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for power in range(-10, 1,2):\n",
    "    L= 2^power\n",
    "    p = Pegasos().fit(X, y, L=L)\n",
    "    print p.coef_\n",
    "    plotDecisionBoundary(X,y, p.predict, [-1,0,1], title='Pegasos SVM, l={}'.format(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
